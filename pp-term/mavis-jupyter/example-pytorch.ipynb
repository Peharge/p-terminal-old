{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f562cce7-dca2-4c3f-a752-7f402052d5d3",
   "metadata": {},
   "source": [
    "# Beschreibung des Codes zur Objekterkennung und Segmentierung mit Mask R-CNN\n",
    "\n",
    "In diesem Beispiel verwenden wir das vortrainierte **Mask R-CNN Modell** aus `torchvision`, um Objekte zu erkennen und ihre Segmentierungs-Masken auf einem Bild zu zeichnen.\n",
    "\n",
    "## Schritt-für-Schritt Erklärung:\n",
    "\n",
    "1. **Bild herunterladen**:\n",
    "   - Wir verwenden die `requests`-Bibliothek, um ein Bild von einer URL herunterzuladen.\n",
    "   - Das Bild wird anschließend mit der `PIL`-Bibliothek geöffnet.\n",
    "\n",
    "2. **Bildvorbereitung**:\n",
    "   - Das heruntergeladene Bild wird mit `torchvision.transforms.ToTensor()` in ein Tensor konvertiert.\n",
    "   - Ein `unsqueeze(0)` wird angewendet, um das Bild auf eine Batch-Dimension zu bringen (wichtig für die Eingabe in das Modell).\n",
    "\n",
    "3. **Laden des Modells**:\n",
    "   - Wir laden das **Mask R-CNN Modell** (`maskrcnn_resnet50_fpn`) aus `torchvision.models.detection`. Dieses Modell gibt nicht nur die Bounding Boxes, sondern auch die **Masken** für die Objekte zurück.\n",
    "   - Das Modell wird in den Evaluierungsmodus (`model.eval()`) versetzt.\n",
    "\n",
    "4. **Durchführen der Inferenz**:\n",
    "   - Die Inferenz erfolgt ohne Gradientenberechnung (`torch.no_grad()`), um die Berechnungen zu optimieren.\n",
    "   - Das Modell gibt eine Reihe von Vorhersagen zurück, einschließlich der Bounding Boxes, Masken und Scores der erkannten Objekte.\n",
    "\n",
    "5. **Verarbeitung der Vorhersagen**:\n",
    "   - Die Bounding Boxes werden aus den Vorhersagen extrahiert und in `long` konvertiert, um sie im Bild zeichnen zu können.\n",
    "   - Die Masken werden durch einen Schwellenwert (0.7) gefiltert, um nur die relevanten Masken anzuzeigen.\n",
    "   \n",
    "6. **Zeichnen der Bounding Boxes und Masken**:\n",
    "   - Mit `torchvision.utils.draw_bounding_boxes` zeichnen wir die Bounding Boxes der erkannten Objekte.\n",
    "   - Mit `torchvision.utils.draw_segmentation_masks` zeichnen wir die Segmentierungsmasken für jedes erkannte Objekt.\n",
    "\n",
    "7. **Bild anzeigen**:\n",
    "   - Das Bild mit den Bounding Boxes und Masken wird schließlich mit `matplotlib` angezeigt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7b29e-a0c6-41e0-8f6d-d3797423cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "\n",
    "# Bild von der URL herunterladen\n",
    "url_image = \"https://www.w3schools.com/w3images/fjords.jpg\"\n",
    "response = requests.get(url_image)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Bild in ein Tensor umwandeln und normalisieren\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Umwandlung von PIL zu Tensor\n",
    "])\n",
    "\n",
    "image = transform(img).unsqueeze(0)  # Unsqueeze für das Batch-Dimension (1, C, H, W)\n",
    "\n",
    "# Vortrainiertes Mask R-CNN Modell laden\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Inferenz durchführen\n",
    "with torch.no_grad():\n",
    "    image = image.to(device)\n",
    "    predictions = model(image)\n",
    "    pred = predictions[0]\n",
    "\n",
    "# Das Bild in den Bereich [0, 255] umwandeln und auf uint8 setzen\n",
    "image = (255.0 * (image - image.min()) / (image.max() - image.min())).to(torch.uint8)\n",
    "image = image.squeeze(0)  # Entfernen der Batch-Dimension\n",
    "\n",
    "# Labels und Boxen vorbereiten\n",
    "pred_labels = [f\"pedestrian: {score:.3f}\" for score in pred[\"scores\"]]\n",
    "pred_boxes = pred[\"boxes\"].long()\n",
    "\n",
    "# Bounding Boxes auf das Bild zeichnen\n",
    "output_image = draw_bounding_boxes(image, pred_boxes, pred_labels, colors=\"red\")\n",
    "\n",
    "# Masken für die Segmentierung zeichnen\n",
    "masks = (pred[\"masks\"] > 0.7).squeeze(1)\n",
    "output_image = draw_segmentation_masks(output_image, masks, alpha=0.5, colors=\"blue\")\n",
    "\n",
    "# Ausgabe des Bildes mit Bounding Boxes und Segmentierungen\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(output_image.permute(1, 2, 0))  # Umordnen von (C, H, W) zu (H, W, C)\n",
    "plt.axis('off')  # Achsen ausschalten\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
